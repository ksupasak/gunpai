mqtt:
  enabled: true
  host: mqtt     # Replace with your broker's IP or hostname
  port: 1883                  # Default MQTT port (use 8883 for SSL)
  # user: <MQTT_USERNAME>       # MQTT username (if required)
  # password: <MQTT_PASSWORD>   # MQTT password (if required)
  topic_prefix: frigate       # Topic prefix for Frigate events
go2rtc:
  streams:
    cam1: # <- for RTSP streams 
      # - rtsp://10.149.1.62:8554/stream/test # <- stream which supports video & aac audio
      - ffmpeg:rtsp://192.168.0.201:554/live    # <- stream which supports video & aac audio
    cam2: # <- for RTSP streams
      - ffmpeg:rtsp://192.168.0.202:554/live    # <- stream which supports video & aac audio
    cam3: # <- for RTSP streams
      - ffmpeg:rtsp://192.168.0.203:554/live    # <- stream which supports video & aac audio
    cam4: # <- for RTSP streams
      - ffmpeg:rtsp://192.168.0.204:554/live    # <- stream which supports video & aac audio z
    bodycam:
      - rtsp://10.149.1.62:8554/stream/test 
cameras:
  cam1: # <------ Name the camera
    enabled: true
    ffmpeg:
      inputs:
        - path: rtsp://127.0.0.1:8554/cam1 # <----- The stream you want to use for detection
          input_args: preset-rtsp-restream

    # cam1: # <- for RTSP streams
    #   # - rtsp://10.149.1.62:8554/stream/test # <- stream which supports video & aac audio
    #   - ffmpeg:rtsp://rtsp-server:8554/live    # <- stream which supports video & aac audio
    # cam2: # <- for RTSP streams
    #   - ffmpeg:rtsp://rtsp-server:8554/live    # <- stream which supports video & aac audio
    # cam3: # <- for RTSP streams
    #   - ffmpeg:rtsp://rtsp-server:8554/live    # <- stream which supports video & aac audio
    # cam4: # <- for RTSP streams
    #   - ffmpeg:rtsp://rtsp-server:8554/live    # <- stream which supports video & aac audio
    #       roles:
    #         - detect
    #         - record
    #         - audio
    # detect:
    #   enabled: false # <---- disable detection until you have a working camera feed
    #   width: 1280
    #   height: 720
    # objects:
    #   track:
    #     - person
    #     - car
    # snapshots:
    #   enabled: true
#     live:
#       bounding_box: true
    # motion:
    #   threshold: 46
    #   contour_area: 9
    #   improve_contrast: 'true'
  cam2: # <------ Name the camera
    enabled: true
    ffmpeg:
      inputs:
        - path: rtsp://127.0.0.1:8554/cam2 # <----- The stream you want to use for detection
          input_args: preset-rtsp-restream
          # roles:
          #   - detect
          #   - record
          #   - audio
  cam3: # <------ Name the camera
    enabled: true
    ffmpeg:
      inputs:
        - path: rtsp://127.0.0.1:8554/cam3 # <----- The stream you want to use for detection
          input_args: preset-rtsp-restream
          # roles:
          #   - detect
          #   - record
          #   - audio
  cam4: # <------ Name the camera
    enabled: true
    ffmpeg:
      inputs:
        - path: rtsp://127.0.0.1:8554/cam4 # <----- The stream you want to use for detection
          input_args: preset-rtsp-restream
          # roles:
          #   - detect
          #   - record
          #   - audio
  cam5: # <------ Name the camera
    enabled: true
    ffmpeg:
      inputs:
        - path: rtsp://127.0.0.1:8554/bodycam # <----- The stream you want to use for detection
          input_args: preset-rtsp-restream
          # roles:
          #   - detect
          #   - record
          #   - audio
    # detect:
    #   enabled: false # <---- disable detection until you have a working camera feed
    #   width: 1280
    #   height: 720
    #   fps: 5
    #   max_disappeared: 25
    # # motion:
    # #   frame_skip: 3
    # objects:
    #   track:
    #     - person
    #     - car
  # cam3: # <------ Name the camera
  #   enabled: false
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://127.0.0.1:8554/camx # <----- The stream you want to use for detection
  # cam4: # <------ Name the camera
  #   enabled: true
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://10.149.1.62:5540/test # <----- The stream you want to use for detection
  #         roles:
  #           - detect
  #           - record
  #   detect:
  #     enabled: true # <---- disable detection until you have a working camera feed
  #     width: 1280
  #     height: 720
  # cam5: # <------ Name the camera
  #   enabled: true
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://10.149.1.62:5540/test # <----- The stream you want to use for detection
  #         roles:
  #           - detect
  #           - record
  #   detect:
  #     enabled: true # <---- disable detection until you have a working camera feed
  #     width: 1280
  #     height: 720
  # cam6: # <------ Name the camera
  #   enabled: true
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://10.149.1.62:5540/test # <----- The stream you want to use for detection
  #         roles:
  #           - detect
  #           - record
  #   detect:
  #     enabled: true # <---- disable detection until you have a working camera feed
  #     width: 1280
  #     height: 720
  # cam7: # <------ Name the camera
  #   enabled: true
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://10.149.1.62:5540/test # <----- The stream you want to use for detection
  #         roles:
  #           - detect
  #           - record
  #   detect:
  #     enabled: true # <---- disable detection until you have a working camera feed
  #     width: 1280
  #     height: 720
  # cam8: # <------ Name the camera
  #   enabled: true
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://10.149.1.62:5540/test # <----- The stream you want to use for detection
  #         roles:
  #           - detect
  #           - record
  #   detect:
  #     enabled: true # <---- disable detection until you have a working camera feed
  #     width: 1280
  #     height: 720
  # cam1B: # <------ Name the camera
  #   enabled: true
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://10.149.1.62:5540/test # <----- The stream you want to use for detection
  #         roles:
  #           - detect
  #           - record
  #   detect:
  #     enabled: true # <---- disable detection until you have a working camera feed
  #     width: 1280
  #     height: 720
  # cam2B: # <------ Name the camera
  #   enabled: true
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://10.149.1.62:5540/test # <----- The stream you want to use for detection
  #         roles:
  #           - detect
  #           - record
  #   detect:
  #     enabled: true # <---- disable detection until you have a working camera feed
  #     width: 1280
  #     height: 720
  # cam3B: # <------ Name the camera
  #   enabled: true
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://10.149.1.62:5540/test # <----- The stream you want to use for detection
  #         roles:
  #           - detect
  #           - record
  #   detect:
  #     enabled: true # <---- disable detection until you have a working camera feed
  #     width: 1280
  #     height: 720
  # cam4B: # <------ Name the camera
  #   enabled: true
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://10.149.1.62:5540/test # <----- The stream you want to use for detection
  #         roles:
  #           - detect
  #           - record
  #   detect:
  #     enabled: true # <---- disable detection until you have a working camera feed
  #     width: 1280
  #     height: 720
  # cam5B: # <------ Name the camera
  #   enabled: true
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://10.149.1.62:5540/test # <----- The stream you want to use for detection
  #         roles:
  #           - detect
  #           - record
  #   detect:
  #     enabled: true # <---- disable detection until you have a working camera feed
  #     width: 1280
  #     height: 720
  # cam6B: # <------ Name the camera
  #   enabled: true
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://10.149.1.62:5540/test # <----- The stream you want to use for detection
  #         roles:
  #           - detect
  #           - record
  #   detect:
  #     enabled: true # <---- disable detection until you have a working camera feed
  #     width: 1280
  #     height: 720
  # cam7B: # <------ Name the camera
  #   enabled: true
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://10.149.1.62:5540/test # <----- The stream you want to use for detection
  #         roles:
  #           - detect
  #           - record
  #   detect:
  #     enabled: true # <---- disable detection until you have a working camera feed
  #     width: 1280
  #     height: 720
  # cam8B: # <------ Name the camera
  #   enabled: true
  #   ffmpeg:
  #     inputs:
  #       - path: rtsp://10.149.1.62:5540/test # <----- The stream you want to use for detection
  #         roles:
  #           - detect
  #           - record
  #   detect:
  #     enabled: true # <---- disable detection until you have a working camera feed
  #     width: 1280
  #     height: 720
birdseye:
  # Optional: Enable birdseye view (default: shown below)
  enabled: false
  # Optional: Restream birdseye via RTSP (default: shown below)
  # NOTE: Enabling this will set birdseye to run 24/7 which may increase CPU usage somewhat.
  restream: false
  # Optional: Width of the output resolution (default: shown below)
  width: 1280
  # Optional: Height of the output resolution (default: shown below)
  height: 720
  # Optional: Encoding quality of the mpeg1 feed (default: shown below)
  # 1 is the highest quality, and 31 is the lowest. Lower quality feeds utilize less CPU resources.
  quality: 8
  # Optional: Mode of the view. Available options are: objects, motion, and continuous
  #   objects - cameras are included if they have had a tracked object within the last 30 seconds
  #   motion - cameras are included if motion was detected in the last 30 seconds
  #   continuous - all cameras are included always
  mode: objects
  # Optional: Threshold for camera activity to stop showing camera (default: shown below)
  inactivity_threshold: 30
  # Optional: Configure the birdseye layout
  layout:
    # Optional: Scaling factor for the layout calculator, range 1.0-5.0 (default: shown below)
    scaling_factor: 2.0
    # Optional: Maximum number of cameras to show at one time, showing the most recent (default: show all cameras)
    max_cameras: 1

# # Optional: Review configuration
# # NOTE: Can be overridden at the camera level
# review:
#   # Optional: alerts configuration
#   alerts:
#     # Optional: labels that qualify as an alert (default: shown below)
#     labels:
#       - car
#       - person
#     # Optional: required zones for an object to be marked as an alert (default: none)
#     # NOTE: when settings required zones globally, this zone must exist on all cameras
#     #       or the config will be considered invalid. In that case the required_zones
#     #       should be configured at the camera level.
#     required_zones:
#       - driveway
#   # Optional: detections configuration
#   detections:
#     # Optional: labels that qualify as a detection (default: all labels that are tracked / listened to)
#     labels:
#       - car
#       - person
#     # Optional: required zones for an object to be marked as a detection (default: none)
#     # NOTE: when settings required zones globally, this zone must exist on all cameras
#     #       or the config will be considered invalid. In that case the required_zones
#     #       should be configured at the camera level.
#     required_zones:
#       - driveway
# # Optional: Motion configuration
# # NOTE: Can be overridden at the camera level
# motion:
#   # Optional: enables detection for the camera (default: True)
#   # NOTE: Motion detection is required for object detection,
#   #       setting this to False and leaving detect enabled
#   #       will result in an error on startup.
#   enabled: true
#   # Optional: The threshold passed to cv2.threshold to determine if a pixel is different enough to be counted as motion. (default: shown below)
#   # Increasing this value will make motion detection less sensitive and decreasing it will make motion detection more sensitive.
#   # The value should be between 1 and 255.
#   threshold: 30
#   # Optional: The percentage of the image used to detect lightning or other substantial changes where motion detection
#   #           needs to recalibrate. (default: shown below)
#   # Increasing this value will make motion detection more likely to consider lightning or ir mode changes as valid motion.
#   # Decreasing this value will make motion detection more likely to ignore large amounts of motion such as a person approaching
#   # a doorbell camera.
#   lightning_threshold: 0.8
#   # Optional: Minimum size in pixels in the resized motion image that counts as motion (default: shown below)
#   # Increasing this value will prevent smaller areas of motion from being detected. Decreasing will
#   # make motion detection more sensitive to smaller moving objects.
#   # As a rule of thumb:
#   #  - 10 - high sensitivity
#   #  - 30 - medium sensitivity
#   #  - 50 - low sensitivity
#   contour_area: 10
#   # Optional: Alpha value passed to cv2.accumulateWeighted when averaging frames to determine the background (default: shown below)
#   # Higher values mean the current frame impacts the average a lot, and a new object will be averaged into the background faster.
#   # Low values will cause things like moving shadows to be detected as motion for longer.
#   # https://www.geeksforgeeks.org/background-subtraction-in-an-image-using-concept-of-running-average/
#   frame_alpha: 0.01
#   # Optional: Height of the resized motion frame  (default: 100)
#   # Higher values will result in more granular motion detection at the expense of higher CPU usage.
#   # Lower values result in less CPU, but small changes may not register as motion.
#   frame_height: 100
#   # Optional: motion mask
#   # NOTE: see docs for more detailed info on creating masks
#   mask: 0.000,0.469,1.000,0.469,1.000,1.000,0.000,1.000
#   # Optional: improve contrast (default: shown below)
#   # Enables dynamic contrast improvement. This should help improve night detections at the cost of making motion detection more sensitive
#   # for daytime.
#   improve_contrast: True
#   # Optional: Delay when updating camera motion through MQTT from ON -> OFF (default: shown below).
#   mqtt_off_delay: 30
record:
  # Optional: Enable recording (default: shown below)
  # WARNING: If recording is disabled in the config, turning it on via
  #          the UI or MQTT later will have no effect.
  enabled: true
  # Optional: Number of minutes to wait between cleanup runs (default: shown below)
  # This can be used to reduce the frequency of deleting recording segments from disk if you want to minimize i/o
  expire_interval: 60
  # Optional: Sync recordings with disk on startup and once a day (default: shown below).
  sync_recordings: false
  # Optional: Retention settings for recording
  retain:
    # Optional: Number of days to retain recordings regardless of events (default: shown below)
    # NOTE: This should be set to 0 and retention should be defined in events section below
    #       if you only want to retain recordings of events.
    days: 0
    # Optional: Mode for retention. Available options are: all, motion, and active_objects
    #   all - save all recording segments regardless of activity
    #   motion - save all recordings segments with any detected motion
    #   active_objects - save all recording segments with active/moving objects
    # NOTE: this mode only applies when the days setting above is greater than 0
    mode: all
  # Optional: Recording Export Settings
  export:
    # Optional: Timelapse Output Args (default: shown below).
    # NOTE: The default args are set to fit 24 hours of recording into 1 hour playback.
    # See https://stackoverflow.com/a/58268695 for more info on how these args work.
    # As an example: if you wanted to go from 24 hours to 30 minutes that would be going
    # from 86400 seconds to 1800 seconds which would be 1800 / 86400 = 0.02.
    # The -r (framerate) dictates how smooth the output video is.
    # So the args would be -vf setpts=0.02*PTS -r 30 in that case.
    timelapse_args: -vf setpts=0.04*PTS -r 30
  # Optional: Recording Preview Settings
  preview:
    # Optional: Quality of recording preview (default: shown below).
    # Options are: very_low, low, medium, high, very_high
    quality: medium
  # Optional: Event recording settings
  events:
    # Optional: Number of seconds before the event to include (default: shown below)
    pre_capture: 5
    # Optional: Number of seconds after the event to include (default: shown below)
    post_capture: 5
    # Optional: Objects to save recordings for. (default: all tracked objects)
    objects:
      - person
    # Optional: Retention settings for recordings of events
    retain:
      # Required: Default retention days (default: shown below)
      default: 10
      # Optional: Mode for retention. (default: shown below)
      #   all - save all recording segments for events regardless of activity
      #   motion - save all recordings segments for events with any detected motion
      #   active_objects - save all recording segments for event with active/moving objects
      #
      # NOTE: If the retain mode for the camera is more restrictive than the mode configured
      #       here, the segments will already be gone by the time this mode is applied.
      #       For example, if the camera retain mode is "motion", the segments without motion are
      #       never stored, so setting the mode to "all" here won't bring them back.
      mode: motion
      # Optional: Per object retention days
      objects:
        person: 15
# detectors:
  # ov:
  #   type: openvino
  #   device: CPU
  #   model:
  #     path:  /gunpai/models/yolov8s_openvino_model/yolov8s.xml
  #     width: 640
  #     height: 640
  #     input_tensor: nchw
  #     input_pixel_format: bgr
  #     model_type: yolox
      # labelmap_path: /path/to/labelmap.txt
  # yolov8:
  #   type: custom
  #   url: http://localhost:5000  # URL of the YOLOv8 server
  # # deepstack:
  #   type: deepstack
  #   api_url: http://deepstack:5000/v1/vision/detection
    #url: http://deepstack:5000  # DeepStack is accessible through its service name in Docker
version: 0.14
camera_groups:
  test:
    order: 1
    icon: LuAlignCenterHorizontal
    cameras:
      - cam1
      - cam2
      - cam3
